struct falcon_attention : public VNodePattern {
    falcon_attention() : VNodePattern("falcon_attention") {}
    OutputVector get(const OutputVector& inputs) override {
        int ii = 0;

        auto qkv_proj = inputs[ii++];           // f32[?,?,9216]  __module.transformer.h.2.self_attention.query_key_value/aten::matmul/MatMul(__module.transformer.h.2.ln_attn/aten::layer_norm/Add, Transpose_677857)
        auto Convert_past_key = inputs[ii++];   // f32[?,128,?,64]  Convert_past_key(Parameter_134655)
        auto Convert_past_value = inputs[ii++]; // f32[?,128,?,64]  Convert_past_value(Parameter_134654)
        auto past_kv_shape = inputs[ii++];      // i32[4]
        auto attn_causal_mask = inputs[ii++];   // f32[?,1,?,?]  __module.transformer.h.0.self_attention/aten::masked_fill/Select(__module.transformer/aten::__or__/LogicalOr, __module.transformer.h.0.self_attention/aten::masked_fill/Broadcast, __module.transformer.h.0.self_attention/aten::mul/Multiply_541)
        auto cos_tab = inputs[ii++];            // f32[1,2048,64]
        auto sin_tab = inputs[ii++];            // f32[1,2048,64]

        // f32[B,L,9216] => [B,L,8,18,64]
        auto head_cnt = Symbol("head_cnt");
        auto head_cnt_per_group = Symbol("h");
        auto head_size = Symbol("head_size");
        auto half_rot_dims = Symbol("half_rot_dims");

        // [B,L,:8,:18-2,:64]  slice out query part => [B,L,8,16,64]
        auto ShapeOf_569949 = GenPattern<opset1::ShapeOf>({qkv_proj}, "i32[3]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_569949(__module.transformer.h.2.self_attention.query_key_value/aten::matmul/MatMul)
        auto Gather_403547 = GenPattern<opset8::Gather>({ShapeOf_569949, {0, 1}, 0}, "i32[2]", {{"batch_dims", 0}});   //  Gather_403547(ShapeOf_569949, Constant_403545, Constant_403546)
        auto ListConstruct_818_Concat = GenPattern<opset1::Concat>({Gather_403547, {-1}, {head_cnt_per_group}, {head_size}}, "i32[5]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_818/Concat(Gather_403547, __module.transformer.h.2.self_attention/prim::ListConstruct_818/Reshape_1, __module.transformer.h.2.self_attention/prim::ListConstruct_818/Reshape_2, __module.transformer.h.2.self_attention/prim::ListConstruct_818/Reshape_3)
        auto view_Reshape = GenPattern<opset1::Reshape>({qkv_proj, ListConstruct_818_Concat}, "f32[?,?,?,18,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::view/Reshape(__module.transformer.h.2.self_attention.query_key_value/aten::matmul/MatMul, __module.transformer.h.2.self_attention/prim::ListConstruct_818/Concat)
        auto slice_Slice = GenPattern<opset1::StridedSlice>({view_Reshape, {0}, {2147483647}, {1}}, "f32[?,?,?,18,64]", {{"begin_mask",  {0} }, {"end_mask",  {0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention/aten::slice/Slice(__module.transformer.h.2.self_attention/aten::view/Reshape, __module.transformer.h.2.self_attention/aten::slice/Unsqueeze_819, __module.transformer.h.2.self_attention/aten::slice/Unsqueeze_820, __module.transformer.h.2.self_attention/aten::slice/Unsqueeze_821)
        auto slice_Slice_827 = GenPattern<opset1::StridedSlice>({slice_Slice, {0, 0}, {0, 2147483647}, {1, 1}}, "f32[?,?,?,18,64]", {{"begin_mask",  {1,0} }, {"end_mask",  {1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention/aten::slice/Slice_827(__module.transformer.h.2.self_attention/aten::slice/Slice, Constant_584922, Constant_584925, Constant_584928)
        auto slice_Slice_833 = GenPattern<opset1::StridedSlice>({slice_Slice_827, {0, 0, 0}, {0, 0, 2147483647}, {1, 1, 1}}, "f32[?,?,?,18,64]", {{"begin_mask",  {1,1,0} }, {"end_mask",  {1,1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention/aten::slice/Slice_833(__module.transformer.h.2.self_attention/aten::slice/Slice_827, Constant_584934, Constant_584937, Constant_584940)
        auto slice_Slice_839 = GenPattern<opset1::StridedSlice>({slice_Slice_833, {0, 0, 0, 0}, {0, 0, 0, -2}, {1, 1, 1, 1}}, "f32[?,?,?,16,64]", {{"begin_mask",  {1,1,1,0} }, {"end_mask",  {1,1,1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention/aten::slice/Slice_839(__module.transformer.h.2.self_attention/aten::slice/Slice_833, Constant_584946, Constant_584949, Constant_584952)

        // [B, L, 128, 64]
        auto ShapeOf_569980 = GenPattern<opset1::ShapeOf>({slice_Slice_839}, "i32[5]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_569980(__module.transformer.h.2.self_attention/aten::slice/Slice_839)
        auto flatten_Slice = GenPattern<opset1::StridedSlice>({ShapeOf_569980, {0}, {2}, {1}}, "i32[2]", {{"begin_mask",  {0} }, {"end_mask",  {0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention/aten::flatten/Slice(ShapeOf_569980, __module.transformer.h.2.self_attention/aten::flatten/Constant_883, __module.transformer.h.2.self_attention/aten::flatten/Unsqueeze, __module.transformer.h.2.self_attention/aten::flatten/Constant_884)
        auto flatten_Concat = GenPattern<opset1::Concat>({flatten_Slice, {-1}, {head_size}}, "i32[4]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/aten::flatten/Concat(__module.transformer.h.2.self_attention/aten::flatten/Slice, __module.transformer.h.2.self_attention/aten::flatten/Constant_888, __module.transformer.h.2.self_attention/aten::flatten/Slice_887)
        auto flatten_Reshape = GenPattern<opset1::Reshape>({slice_Slice_839, flatten_Concat}, "f32[?,?,?,64]", {{"special_zero", 1}});   //  __module.transformer.h.2.self_attention/aten::flatten/Reshape(__module.transformer.h.2.self_attention/aten::slice/Slice_839, __module.transformer.h.2.self_attention/aten::flatten/Concat)

        // [B, 128, L, 64] => [B*H, L, 64]
        auto transpose_Transpose = GenPattern<opset1::Transpose>({flatten_Reshape, {0, 2, 1, 3}}, "f32[?,?,?,64]");   //  __module.transformer.h.2.self_attention/aten::transpose/Transpose(__module.transformer.h.2.self_attention/aten::flatten/Reshape, __module.transformer.h.2.self_attention/aten::transpose/ScatterElementsUpdate)
        auto ShapeOf_570007 = GenPattern<opset1::ShapeOf>({flatten_Reshape}, "i32[4]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_570007(__module.transformer.h.2.self_attention/aten::flatten/Reshape)
        auto size_Gather_919 = GenPattern<opset8::Gather>({ShapeOf_570007, 0, 0}, "i32[]", {{"batch_dims", 0}});   //  __module.transformer.h.2.self_attention/aten::size/Gather_919(ShapeOf_570007, 249, __module.transformer.h.2.self_attention/aten::size/Constant_918)
        auto mul_Multiply = GenPattern<opset1::Multiply>({size_Gather_919, head_cnt}, "i32[]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention/aten::mul/Multiply(__module.transformer.h.2.self_attention/aten::size/Gather_919, 264)
        auto ListConstruct_931_Reshape = GenPattern<opset1::Reshape>({mul_Multiply, {-1}}, "i32[1]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_931/Reshape(__module.transformer.h.2.self_attention/aten::mul/Multiply, Constant_146098)
        auto size_Gather_922 = GenPattern<opset8::Gather>({ShapeOf_570007, {1}, 0}, "i32[1]", {{"batch_dims", 0}});   //  __module.transformer.h.2.self_attention/aten::size/Gather_922(ShapeOf_570007, Constant_401490, __module.transformer.h.2.self_attention/aten::size/Constant_921)
        auto ListConstruct_931_Concat = GenPattern<opset1::Concat>({ListConstruct_931_Reshape, size_Gather_922, {head_size}}, "i32[3]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_931/Concat(__module.transformer.h.2.self_attention/prim::ListConstruct_931/Reshape, __module.transformer.h.2.self_attention/aten::size/Gather_922, __module.transformer.h.2.self_attention/prim::ListConstruct_931/Reshape_1)
        auto reshape_Reshape = GenPattern<opset1::Reshape>({transpose_Transpose, ListConstruct_931_Concat}, "f32[?,?,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::reshape/Reshape(__module.transformer.h.2.self_attention/aten::transpose/Transpose, __module.transformer.h.2.self_attention/prim::ListConstruct_931/Concat)

        auto view_Reshape_147 = GenPattern<opset1::Reshape>({Convert_past_key, past_kv_shape}, "f32[?,?,64]", {{"special_zero", 0}});   //  __module.transformer/aten::view/Reshape_147(Convert_past_key, __module.transformer/prim::ListConstruct_143/Concat)

        auto ShapeOf_570096 = GenPattern<opset1::ShapeOf>({view_Reshape_147}, "i32[3]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_570096(__module.transformer/aten::view/Reshape_147)
        auto rot_size_Gather_964 = GenPattern<opset8::Gather>({ShapeOf_570096, 1, 0}, "i32[]", {{"batch_dims", 0}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::size/Gather_964(ShapeOf_570096, 250, __module.transformer.h.2.self_attention.maybe_rotary/aten::size/Constant_963)
        auto rot_slice_Unsqueeze_965 = GenPattern<opset1::Reshape>({rot_size_Gather_964, {1}}, "i32[1]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Unsqueeze_965(__module.transformer.h.2.self_attention.maybe_rotary/aten::size/Gather_964, Constant_426832)
        auto ScatterUpdate_584959 = GenPattern<opset3::ScatterUpdate>({{0, 0}, {1}, rot_slice_Unsqueeze_965, {0}}, "i32[2]");   //  ScatterUpdate_584959(Constant_584958, Constant_584957, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Unsqueeze_965, Constant_584956)
        auto ShapeOf_570100 = GenPattern<opset1::ShapeOf>({reshape_Reshape}, "i32[3]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_570100(__module.transformer.h.2.self_attention/aten::reshape/Reshape)
        auto rot_size_Gather = GenPattern<opset8::Gather>({ShapeOf_570100, {1}, 0}, "i32[1]", {{"batch_dims", 0}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::size/Gather(ShapeOf_570100, Constant_401495, __module.transformer.h.2.self_attention.maybe_rotary/aten::size/Constant)
        auto rot_add_Add = GenPattern<opset1::Add>({rot_size_Gather, rot_size_Gather_964}, "i32[1]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::add/Add(__module.transformer.h.2.self_attention.maybe_rotary/aten::size/Gather, __module.transformer.h.2.self_attention.maybe_rotary/aten::size/Gather_964)
        auto ScatterUpdate_584961 = GenPattern<opset3::ScatterUpdate>({{0, 0}, {1}, rot_add_Add, {0}}, "i32[2]");   //  ScatterUpdate_584961(Constant_584960, Constant_584957, __module.transformer.h.2.self_attention.maybe_rotary/aten::add/Add, Constant_584956)
        auto rot_slice_Slice = GenPattern<opset1::StridedSlice>({cos_tab, ScatterUpdate_584959, ScatterUpdate_584961, {1, 1}}, "f32[1,..2048,64]", {{"begin_mask",  {1,0} }, {"end_mask",  {1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice(cos_tab, ScatterUpdate_584959, ScatterUpdate_584961, Constant_584964)
        
        // *cos
        auto rot_mul_Multiply = GenPattern<opset1::Multiply>({reshape_Reshape, rot_slice_Slice}, "f32[?,?,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply(__module.transformer.h.2.self_attention/aten::reshape/Reshape, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice)
        auto rot_slice_Slice_989 = GenPattern<opset1::StridedSlice>({reshape_Reshape, {0, 0, half_rot_dims}, {0, 0, 2147483647}, {1, 1, 1}}, "f32[?,?,32]", {{"begin_mask",  {1,1,0} }, {"end_mask",  {1,1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_989(__module.transformer.h.2.self_attention/aten::reshape/Reshape, ScatterUpdate_585105, Constant_585108, Constant_585111)

        
        auto rot_neg_Multiply = GenPattern<opset1::Multiply>({rot_slice_Slice_989, {-1}}, "f32[?,?,32]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::neg/Multiply(__module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_989, Constant_698240)
        auto rot_slice_Slice_983 = GenPattern<opset1::StridedSlice>({reshape_Reshape, {0, 0, 0}, {0, 0, half_rot_dims}, {1, 1, 1}}, "f32[?,?,32]", {{"begin_mask",  {1,1,0} }, {"end_mask",  {1,1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_983(__module.transformer.h.2.self_attention/aten::reshape/Reshape, Constant_585169, ScatterUpdate_585171, Constant_585174)
        auto rot_cat_Concat = GenPattern<opset1::Concat>({rot_neg_Multiply, rot_slice_Slice_983}, "f32[?,?,64]", {{"axis", -1}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::cat/Concat(__module.transformer.h.2.self_attention.maybe_rotary/aten::neg/Multiply, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_983)
        auto ScatterUpdate_585231 = GenPattern<opset3::ScatterUpdate>({{0, 0}, {1}, rot_slice_Unsqueeze_965, {0}}, "i32[2]");   //  ScatterUpdate_585231(Constant_585230, Constant_585229, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Unsqueeze_965, Constant_585228)
        auto ScatterUpdate_585233 = GenPattern<opset3::ScatterUpdate>({{0, 0}, {1}, rot_add_Add, {0}}, "i32[2]");   //  ScatterUpdate_585233(Constant_585232, Constant_585229, __module.transformer.h.2.self_attention.maybe_rotary/aten::add/Add, Constant_585228)
        auto rot_slice_Slice_973 = GenPattern<opset1::StridedSlice>({sin_tab, ScatterUpdate_585231, ScatterUpdate_585233, {1, 1}}, "f32[1,..2048,64]", {{"begin_mask",  {1,0} }, {"end_mask",  {1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_973(sin_tab, ScatterUpdate_585231, ScatterUpdate_585233, Constant_585236)
        auto rot_mul_Multiply_991 = GenPattern<opset1::Multiply>({rot_cat_Concat, rot_slice_Slice_973}, "f32[?,?,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply_991(__module.transformer.h.2.self_attention.maybe_rotary/aten::cat/Concat, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_973)
        auto rot_add_Add_994 = GenPattern<opset1::Add>({rot_mul_Multiply, rot_mul_Multiply_991}, "f32[?,?,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::add/Add_994(__module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply, __module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply_991)

        // Q*(1/sqrt(head_size))
        // => B,H,L,S
        auto ListConstruct_1055_Reshape = GenPattern<opset1::Reshape>({size_Gather_919, {-1}}, "i32[1]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_1055/Reshape(__module.transformer.h.2.self_attention/aten::size/Gather_919, Constant_146100)
        auto ListConstruct_1036_Concat = GenPattern<opset1::Concat>({ListConstruct_1055_Reshape, {head_cnt}, {-1}, {head_size}}, "i32[4]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_1036/Concat(__module.transformer.h.2.self_attention/prim::ListConstruct_1055/Reshape, __module.transformer.h.2.self_attention/prim::ListConstruct_1036/Reshape_0, __module.transformer.h.2.self_attention/prim::ListConstruct_1036/Reshape_1, __module.transformer.h.2.self_attention/prim::ListConstruct_1036/Reshape_2)
        auto reshape_Reshape_1037 = GenPattern<opset1::Reshape>({rot_add_Add_994, ListConstruct_1036_Concat}, "f32[?,128,?,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::reshape/Reshape_1037(__module.transformer.h.2.self_attention.maybe_rotary/aten::add/Add_994, __module.transformer.h.2.self_attention/prim::ListConstruct_1036/Concat)
        auto ShapeOf_570396 = GenPattern<opset1::ShapeOf>({reshape_Reshape_1037}, "i32[4]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_570396(__module.transformer.h.2.self_attention/aten::reshape/Reshape_1037)
        auto scaled_dot_product_attention_Gather = GenPattern<opset8::Gather>({ShapeOf_570396, 3, 0}, "i32[]", {{"batch_dims", 0}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Gather(ShapeOf_570396, Constant_494188, __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Constant_1042)
        auto scaled_dot_product_attention_ConvertLike = GenPattern<opset1::Convert>({scaled_dot_product_attention_Gather}, "f32[]", {{"destination_type", "f32"}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/ConvertLike(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Gather)
        auto scaled_dot_product_attention_Sqrt = GenPattern<opset1::Sqrt>({scaled_dot_product_attention_ConvertLike}, "f32[]");   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Sqrt(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/ConvertLike)
        auto scaled_dot_product_attention_Divide = GenPattern<opset1::Power>({scaled_dot_product_attention_Sqrt, -1.0f}, "f32[]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Divide(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Sqrt, Constant_494189)
        auto scaled_dot_product_attention_Multiply = GenPattern<opset1::Multiply>({reshape_Reshape_1037, scaled_dot_product_attention_Divide}, "f32[?,128,?,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Multiply(__module.transformer.h.2.self_attention/aten::reshape/Reshape_1037, __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Divide)

        // second last head is key in group [B,L,Group,1,64]
        auto index_845_Gather = GenPattern<opset8::Gather>({slice_Slice_833, {head_cnt_per_group-2}, 3}, "f32[?,?,?,1,64]", {{"batch_dims", 0}});   //  __module.transformer.h.2.self_attention/aten::index_845/Gather(__module.transformer.h.2.self_attention/aten::slice/Slice_833, Constant_494201, Constant_42522)

        // broadcast key from 1 to 16 [B,L,Group,1,64] => [B,L,Group,16,64]
        auto Gather_403556 = GenPattern<opset8::Gather>({ShapeOf_569980, {0, 1, 2}, 0}, "i32[3]", {{"batch_dims", 0}});   //  Gather_403556(ShapeOf_569980, Constant_403554, Constant_403555)
        auto ListConstruct_870_Concat = GenPattern<opset1::Concat>({Gather_403556, {head_cnt_per_group-2}, {head_size}}, "i32[5]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_870/Concat(Gather_403556, __module.transformer.h.2.self_attention/prim::ListConstruct_870/Reshape_2, __module.transformer.h.2.self_attention/prim::ListConstruct_870/Reshape_3)
        auto Constant_548225 = GenConst({0}, "u8[]");
        auto Broadcast_548226 = GenPattern<opset1::Broadcast>({{1.0f}, ListConstruct_870_Concat, Constant_548225}, "f32[?,?,?,16,64]", {{"mode", "numpy"}});   //  Broadcast_548226(Constant_548224, __module.transformer.h.2.self_attention/prim::ListConstruct_870/Concat, Constant_548225)
        auto broadcast_to_Broadcast_873 = GenPattern<opset1::Multiply>({index_845_Gather, Broadcast_548226}, "f32[?,?,?,16,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention/aten::broadcast_to/Broadcast_873(__module.transformer.h.2.self_attention/aten::index_845/Gather, Broadcast_548226)

        auto ShapeOf_570424 = GenPattern<opset1::ShapeOf>({broadcast_to_Broadcast_873}, "i32[5]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_570424(__module.transformer.h.2.self_attention/aten::broadcast_to/Broadcast_873)
        auto flatten_Slice_898 = GenPattern<opset1::StridedSlice>({ShapeOf_570424, {0}, {2}, {1}}, "i32[2]", {{"begin_mask",  {0} }, {"end_mask",  {0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention/aten::flatten/Slice_898(ShapeOf_570424, __module.transformer.h.2.self_attention/aten::flatten/Constant_893, __module.transformer.h.2.self_attention/aten::flatten/Unsqueeze_896, __module.transformer.h.2.self_attention/aten::flatten/Constant_894)
        auto flatten_Concat_901 = GenPattern<opset1::Concat>({flatten_Slice_898, {-1}, {head_size}}, "i32[4]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/aten::flatten/Concat_901(__module.transformer.h.2.self_attention/aten::flatten/Slice_898, __module.transformer.h.2.self_attention/aten::flatten/Constant_900, __module.transformer.h.2.self_attention/aten::flatten/Slice_899)
        auto flatten_Reshape_902 = GenPattern<opset1::Reshape>({broadcast_to_Broadcast_873, flatten_Concat_901}, "f32[?,?,?,64]", {{"special_zero", 1}});   //  __module.transformer.h.2.self_attention/aten::flatten/Reshape_902(__module.transformer.h.2.self_attention/aten::broadcast_to/Broadcast_873, __module.transformer.h.2.self_attention/aten::flatten/Concat_901)
        auto transpose_Transpose_945 = GenPattern<opset1::Transpose>({flatten_Reshape_902, {0, 2, 1, 3}}, "f32[?,?,?,64]");   //  __module.transformer.h.2.self_attention/aten::transpose/Transpose_945(__module.transformer.h.2.self_attention/aten::flatten/Reshape_902, __module.transformer.h.2.self_attention/aten::transpose/ScatterElementsUpdate_944)
        auto reshape_Reshape_946 = GenPattern<opset1::Reshape>({transpose_Transpose_945, ListConstruct_931_Concat}, "f32[?,?,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::reshape/Reshape_946(__module.transformer.h.2.self_attention/aten::transpose/Transpose_945, __module.transformer.h.2.self_attention/prim::ListConstruct_931/Concat)
        
        // *cos
        auto rot_mul_Multiply_995 = GenPattern<opset1::Multiply>({reshape_Reshape_946, rot_slice_Slice}, "f32[?,?,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply_995(__module.transformer.h.2.self_attention/aten::reshape/Reshape_946, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice)
        
        auto rot_slice_Slice_1013 = GenPattern<opset1::StridedSlice>({reshape_Reshape_946, {0, 0, half_rot_dims}, {0, 0, 2147483647}, {1, 1, 1}}, "f32[?,?,32]", {{"begin_mask",  {1,1,0} }, {"end_mask",  {1,1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_1013(__module.transformer.h.2.self_attention/aten::reshape/Reshape_946, ScatterUpdate_585379, Constant_585382, Constant_585385)
        auto rot_neg_Multiply_1016 = GenPattern<opset1::Multiply>({rot_slice_Slice_1013, {-1.0f}}, "f32[?,?,32]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::neg/Multiply_1016(__module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_1013, Constant_698241)
        auto rot_slice_Slice_1007 = GenPattern<opset1::StridedSlice>({reshape_Reshape_946, {0, 0, 0}, {0, 0, half_rot_dims}, {1, 1, 1}}, "f32[?,?,32]", {{"begin_mask",  {1,1,0} }, {"end_mask",  {1,1,0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_1007(__module.transformer.h.2.self_attention/aten::reshape/Reshape_946, Constant_585443, ScatterUpdate_585445, Constant_585448)
        auto rot_cat_Concat_1020 = GenPattern<opset1::Concat>({rot_neg_Multiply_1016, rot_slice_Slice_1007}, "f32[?,?,64]", {{"axis", -1}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::cat/Concat_1020(__module.transformer.h.2.self_attention.maybe_rotary/aten::neg/Multiply_1016, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_1007)
        // *sin
        auto rot_mul_Multiply_1022 = GenPattern<opset1::Multiply>({rot_cat_Concat_1020, rot_slice_Slice_973}, "f32[?,?,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply_1022(__module.transformer.h.2.self_attention.maybe_rotary/aten::cat/Concat_1020, __module.transformer.h.2.self_attention.maybe_rotary/aten::slice/Slice_973)
        // x*cos + [-x2,x1]*sin
        auto rot_add_Add_1026 = GenPattern<opset1::Add>({rot_mul_Multiply_995, rot_mul_Multiply_1022}, "f32[?,?,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention.maybe_rotary/aten::add/Add_1026(__module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply_995, __module.transformer.h.2.self_attention.maybe_rotary/aten::mul/Multiply_1022)

        // concat past key (so past key'head is broadcasted)
        auto cat_Concat = GenPattern<opset1::Concat>({view_Reshape_147, rot_add_Add_1026}, "f32[?,?,64]", {{"axis", 1}});   //  __module.transformer.h.2.self_attention/aten::cat/Concat(__module.transformer/aten::view/Reshape_147, __module.transformer.h.2.self_attention.maybe_rotary/aten::add/Add_1026)
        auto reshape_Reshape_1038 = GenPattern<opset1::Reshape>({cat_Concat, ListConstruct_1036_Concat}, "f32[?,128,?,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::reshape/Reshape_1038(__module.transformer.h.2.self_attention/aten::cat/Concat, __module.transformer.h.2.self_attention/prim::ListConstruct_1036/Concat)

        auto scaled_dot_product_attention_MatMul = GenPattern<opset1::MatMul>({scaled_dot_product_attention_Multiply, reshape_Reshape_1038}, "f32[?,128,?,?]", {{"transpose_a", 0}, {"transpose_b", 1}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/MatMul(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Multiply, __module.transformer.h.2.self_attention/aten::reshape/Reshape_1038)
        auto scaled_dot_product_attention_Add_1051 = GenPattern<opset1::Add>({scaled_dot_product_attention_MatMul, attn_causal_mask}, "f32[?,128,?,?]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Add_1051(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/MatMul, __module.transformer.h.0.self_attention/aten::masked_fill/Select)
        auto scaled_dot_product_attention_Softmax = GenPattern<opset1::Softmax>({scaled_dot_product_attention_Add_1051}, "f32[?,128,?,?]", {{"axis", 3}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Softmax(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Add_1051)

        auto view_Reshape_148 = GenPattern<opset1::Reshape>({Convert_past_value, past_kv_shape}, "f32[?,?,64]", {{"special_zero", 0}});   //  __module.transformer/aten::view/Reshape_148(Convert_past_value, __module.transformer/prim::ListConstruct_143/Concat)

        // the last head per group is value: [B,L,8,1,64]
        auto index_852_Gather = GenPattern<opset8::Gather>({slice_Slice_833, {head_cnt_per_group-1}, 3}, "f32[?,?,?,1,64]", {{"batch_dims", 0}});   //  __module.transformer.h.2.self_attention/aten::index_852/Gather(__module.transformer.h.2.self_attention/aten::slice/Slice_833, Constant_494214, Constant_42525)
        
        // broad cast from 1 to 16
        auto Constant_548231 = GenConst({0}, "u8[]");
        auto Broadcast_548232 = GenPattern<opset1::Broadcast>({{1.0f}, ListConstruct_870_Concat, Constant_548231}, "f32[?,?,?,16,64]", {{"mode", "numpy"}});   //  Broadcast_548232(Constant_548230, __module.transformer.h.2.self_attention/prim::ListConstruct_870/Concat, Constant_548231)
        auto broadcast_to_Broadcast_881 = GenPattern<opset1::Multiply>({index_852_Gather, Broadcast_548232}, "f32[?,?,?,16,64]", {{"auto_broadcast", "numpy"}});   //  __module.transformer.h.2.self_attention/aten::broadcast_to/Broadcast_881(__module.transformer.h.2.self_attention/aten::index_852/Gather, Broadcast_548232)
        auto ShapeOf_570460 = GenPattern<opset1::ShapeOf>({broadcast_to_Broadcast_881}, "i32[5]", {{"type_relax", 1}, {"input_data_types", "{}"}, {"output_data_types", "{i32}"}});   //  ShapeOf_570460(__module.transformer.h.2.self_attention/aten::broadcast_to/Broadcast_881)
        auto flatten_Slice_912 = GenPattern<opset1::StridedSlice>({ShapeOf_570460, {0}, {2}, {1}}, "i32[2]", {{"begin_mask",  {0} }, {"end_mask",  {0} }, {"new_axis_mask",  {} }, {"shrink_axis_mask",  {} }, {"ellipsis_mask",  {} }});   //  __module.transformer.h.2.self_attention/aten::flatten/Slice_912(ShapeOf_570460, __module.transformer.h.2.self_attention/aten::flatten/Constant_907, __module.transformer.h.2.self_attention/aten::flatten/Unsqueeze_910, __module.transformer.h.2.self_attention/aten::flatten/Constant_908)
        auto flatten_Concat_915 = GenPattern<opset1::Concat>({flatten_Slice_912, {-1}, {head_size}}, "i32[4]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/aten::flatten/Concat_915(__module.transformer.h.2.self_attention/aten::flatten/Slice_912, __module.transformer.h.2.self_attention/aten::flatten/Constant_914, __module.transformer.h.2.self_attention/aten::flatten/Slice_913)
        auto flatten_Reshape_916 = GenPattern<opset1::Reshape>({broadcast_to_Broadcast_881, flatten_Concat_915}, "f32[?,?,?,64]", {{"special_zero", 1}});   //  __module.transformer.h.2.self_attention/aten::flatten/Reshape_916(__module.transformer.h.2.self_attention/aten::broadcast_to/Broadcast_881, __module.transformer.h.2.self_attention/aten::flatten/Concat_915)
        auto transpose_Transpose_960 = GenPattern<opset1::Transpose>({flatten_Reshape_916, {0, 2, 1, 3}}, "f32[?,?,?,64]");   //  __module.transformer.h.2.self_attention/aten::transpose/Transpose_960(__module.transformer.h.2.self_attention/aten::flatten/Reshape_916, __module.transformer.h.2.self_attention/aten::transpose/ScatterElementsUpdate_959)
        auto reshape_Reshape_961 = GenPattern<opset1::Reshape>({transpose_Transpose_960, ListConstruct_931_Concat}, "f32[?,?,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::reshape/Reshape_961(__module.transformer.h.2.self_attention/aten::transpose/Transpose_960, __module.transformer.h.2.self_attention/prim::ListConstruct_931/Concat)

        // concat past value
        auto cat_Concat_1033 = GenPattern<opset1::Concat>({view_Reshape_148, reshape_Reshape_961}, "f32[?,?,64]", {{"axis", 1}});   //  __module.transformer.h.2.self_attention/aten::cat/Concat_1033(__module.transformer/aten::view/Reshape_148, __module.transformer.h.2.self_attention/aten::reshape/Reshape_961)
        auto reshape_Reshape_1039 = GenPattern<opset1::Reshape>({cat_Concat_1033, ListConstruct_1036_Concat}, "f32[?,128,?,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::reshape/Reshape_1039(__module.transformer.h.2.self_attention/aten::cat/Concat_1033, __module.transformer.h.2.self_attention/prim::ListConstruct_1036/Concat)

        // W*V
        auto scaled_dot_product_attention_MatMul_1052 = GenPattern<opset1::MatMul>({scaled_dot_product_attention_Softmax, reshape_Reshape_1039}, "f32[?,128,?,64]", {{"transpose_a", 0}, {"transpose_b", 0}});   //  __module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/MatMul_1052(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/Softmax, __module.transformer.h.2.self_attention/aten::reshape/Reshape_1039)
        auto ListConstruct_1055_Concat = GenPattern<opset1::Concat>({ListConstruct_1055_Reshape, {head_cnt}, size_Gather_922, {head_size}}, "i32[4]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_1055/Concat(__module.transformer.h.2.self_attention/prim::ListConstruct_1055/Reshape, __module.transformer.h.2.self_attention/prim::ListConstruct_1055/Reshape_0, __module.transformer.h.2.self_attention/aten::size/Gather_922, __module.transformer.h.2.self_attention/prim::ListConstruct_1055/Reshape_2)
        auto view_Reshape_1056 = GenPattern<opset1::Reshape>({scaled_dot_product_attention_MatMul_1052, ListConstruct_1055_Concat}, "f32[?,128,?,64]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::view/Reshape_1056(__module.transformer.h.2.self_attention/aten::scaled_dot_product_attention/MatMul_1052, __module.transformer.h.2.self_attention/prim::ListConstruct_1055/Concat)
        auto permute_Transpose = GenPattern<opset1::Transpose>({view_Reshape_1056, {0, 2, 1, 3}}, "f32[?,?,128,64]");   //  __module.transformer.h.2.self_attention/aten::permute/Transpose(__module.transformer.h.2.self_attention/aten::view/Reshape_1056, 242)
        auto ListConstruct_1059_Concat = GenPattern<opset1::Concat>({ListConstruct_1055_Reshape, size_Gather_922, {8192}}, "i32[3]", {{"axis", 0}});   //  __module.transformer.h.2.self_attention/prim::ListConstruct_1059/Concat(__module.transformer.h.2.self_attention/prim::ListConstruct_1055/Reshape, __module.transformer.h.2.self_attention/aten::size/Gather_922, __module.transformer.h.2.self_attention/prim::ListConstruct_1059/Reshape_1)
        auto reshape_Reshape_1060 = GenPattern<opset1::Reshape>({permute_Transpose, ListConstruct_1059_Concat}, "f32[?,?,8192]", {{"special_zero", 0}});   //  __module.transformer.h.2.self_attention/aten::reshape/Reshape_1060(__module.transformer.h.2.self_attention/aten::permute/Transpose, __module.transformer.h.2.self_attention/prim::ListConstruct_1059/Concat)

        // current pattern matching only find along first output, other output must already contained in the path
        return {reshape_Reshape_1060, cat_Concat, cat_Concat_1033};
    }
};
