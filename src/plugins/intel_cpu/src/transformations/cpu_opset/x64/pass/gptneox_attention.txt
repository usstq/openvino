OutputVector gptneox_attention(const OutputVector& inputs) {
    OutputVector all_outputs;
    int ii = 0;
    auto input_ids = inputs[ii++]; //GenInput("i32[?,?]");
    auto attention_mask = inputs[ii++];// GenPattern<opset1::Parameter>({}, "i32[?,?]", {{"shape", "[?,?]"}, {"element_type", "i32"}});
    auto past_key_values_1_key = inputs[ii++]; //GenPattern<opset1::Parameter>({}, "f32[?,8,?,64]", {{"shape", "[?,8,?,64]"}, {"element_type", "f32"}});
    auto past_key_values_1_value = inputs[ii++]; //GenPattern<opset1::Parameter>({}, "f32[?,8,?,64]", {{"shape", "[?,8,?,64]"}, {"element_type", "f32"}});
    auto past_key_values_0_key = inputs[ii++];
    auto _gpt_neox_layers_1_attention_query_key_value_Add = inputs[ii++]; //GenPattern<FullyConnectedNode>({_gpt_neox_layers_1_input_layernorm_Add_1, Constant_40943, Constant_53989}, "f32[?,?,1536]", {{"out-rank", "?"}, {"out-type", "f32"}});
    auto gpt_neox_layers_1_attention_bias = inputs[ii++];// GenPattern<opset1::Constant>({/*1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...4194304in total*/}, "u8[1,1,2048,2048]");
    auto _gpt_neox_layers_0_attention_rotary_emb_Constant = inputs[ii++]; //GenPattern<opset1::Constant>({/*1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.540302,0.950415,0.995004,0.9995,0.99995,0.999995,...32768in total*/}, "f32[1,1,2048,16]");
    auto _gpt_neox_layers_0_attention_rotary_emb_Constant_5 = inputs[ii++]; //GenPattern<opset1::Constant>({/*0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.841471,0.310984,0.0998334,0.0316175,0.00999983,...32768in total*/}, "f32[1,1,2048,16]");

    auto past_key_values_0_key_shape_n2_ = GenPattern<DimOfNode>({past_key_values_0_key}, "i32[]", {{"axis", -2}, {"output_scalar", 1}});
    auto input_ids_shape_1_ = GenPattern<DimOfNode>({input_ids}, "i32[]", {{"axis", 1}, {"output_scalar", 1}});
    auto _gpt_neox_Add = GenPattern<opset1::Add>({input_ids_shape_1_, past_key_values_0_key_shape_n2_}, "i32[]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_Range = GenPattern<opset4::Range>({past_key_values_0_key_shape_n2_, _gpt_neox_Add, 1}, "i32[?]", {{"output_type", "i32"}});
    auto _gpt_neox_Unsqueeze = GenPattern<opset1::Reshape>({_gpt_neox_Range, {1, -1}}, "i32[1,?]", {{"special_zero", 0}});
    auto input_ids_shape__1__ = GenPattern<DimOfNode>({input_ids}, "i32[1]", {{"axis", 1}, {"output_scalar", 0}});
    auto _gpt_neox_Concat = GenPattern<opset1::Concat>({{-1}, input_ids_shape__1__}, "i32[2]", {{"axis", 0}});
    auto _gpt_neox_Reshape = GenPattern<opset1::Reshape>({_gpt_neox_Unsqueeze, _gpt_neox_Concat}, "i32[?,?]", {{"special_zero", 1}});
    auto _gpt_neox_layers_0_attention_Unsqueeze_3 = GenPattern<opset1::Unsqueeze>({_gpt_neox_Reshape, {1, 3}}, "i32[?,1,?,1]");

    auto input_ids_shape__0__ = GenPattern<DimOfNode>({input_ids}, "i32[1]", {{"axis", 0}, {"output_scalar", 0}});
    auto _gpt_neox_Concat_1 = GenPattern<opset1::Concat>({input_ids_shape__0__, {-1}}, "i32[2]", {{"axis", 0}});
    auto _gpt_neox_Reshape_1 = GenPattern<opset1::Reshape>({attention_mask, _gpt_neox_Concat_1}, "i32[?,?]", {{"special_zero", 1}});
    auto _gpt_neox_Unsqueeze_4 = GenPattern<opset1::Unsqueeze>({_gpt_neox_Reshape_1, {1, 2}}, "i32[?,1,1,?]");
    auto _gpt_neox_Cast_2 = GenPattern<opset1::Convert>({_gpt_neox_Unsqueeze_4}, "f32[?,1,1,?]", {{"destination_type", "f32"}});
    auto Multiply_42419 = GenPattern<PowerStaticNode>({_gpt_neox_Cast_2}, "f32[?,1,1,?]", {{"scale", FLT_MAX}, {"power", 1.0}, {"shift", 0.0}, {"out-type", "f32"}});
    auto _gpt_neox_Mul = GenPattern<PowerStaticNode>({Multiply_42419}, "f32[?,1,1,?]", {{"scale", 1.0}, {"power", 1.0}, {"shift", -FLT_MAX}, {"out-type", "f32"}});

    auto _gpt_neox_layers_1_attention_Reshape = GenPattern<opset1::Reshape>({_gpt_neox_layers_1_attention_query_key_value_Add, {0, 0, 8, 192}}, "f32[?,?,8,192]", {{"special_zero", 1}});
    auto _gpt_neox_layers_1_attention_Slice_1 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Reshape, {64}, {128}, {1}, {3}}, "f32[?,?,8,64]");
    auto _gpt_neox_layers_1_attention_Transpose_1 = GenPattern<opset1::Transpose>({_gpt_neox_layers_1_attention_Slice_1, {0, 2, 1, 3}}, "f32[?,8,?,64]");
    auto _gpt_neox_layers_1_attention_Slice_5 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Transpose_1, {0}, {16}, {1}, {3}}, "f32[?,8,?,16]");
    auto _gpt_neox_layers_1_attention_Transpose_1_shape_2_ = GenPattern<DimOfNode>({_gpt_neox_layers_1_attention_Transpose_1}, "i32[1]", {{"axis", 2}, {"output_scalar", 0}});
    auto past_key_values_1_key_shape_2_ = GenPattern<DimOfNode>({past_key_values_1_key}, "i32[1]", {{"axis", 2}, {"output_scalar", 0}});
    auto _gpt_neox_layers_1_attention_Add = GenPattern<opset1::Add>({_gpt_neox_layers_1_attention_Transpose_1_shape_2_, past_key_values_1_key_shape_2_}, "i32[1]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_rotary_emb_Slice = GenPattern<opset8::Slice>({_gpt_neox_layers_0_attention_rotary_emb_Constant, {0}, _gpt_neox_layers_1_attention_Add, {1}, {0}}, "f32[..1,1,2048,16]");
    auto Constant_46607 = GenConst({1}, "i32[1,1,1,1]");
    auto _gpt_neox_layers_1_attention_Expand = GenPattern<opset1::Multiply>({_gpt_neox_layers_0_attention_Unsqueeze_3, Constant_46607}, "i32[?,1,?,1]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Tile = GenPattern<opset1::Tile>({_gpt_neox_layers_1_attention_Expand, {1, 1, 1, 16}}, "i32[?,1,?,16]");
    auto _gpt_neox_layers_1_attention_Tile_shape__0__ = GenPattern<DimOfNode>({_gpt_neox_layers_1_attention_Tile}, "i32[1]", {{"axis", 0}, {"output_scalar", 0}});
    auto _gpt_neox_layers_1_attention_Concat_4 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Tile_shape__0__, {1}, {1}, {1}}, "i32[4]", {{"axis", 0}});
    auto _gpt_neox_layers_1_attention_Tile_1 = GenPattern<opset1::Tile>({_gpt_neox_layers_1_attention_rotary_emb_Slice, _gpt_neox_layers_1_attention_Concat_4}, "f32[?,1,2048,16]");
    auto _gpt_neox_layers_1_attention_GatherElements = GenPattern<opset6::GatherElements>({_gpt_neox_layers_1_attention_Tile_1, _gpt_neox_layers_1_attention_Tile}, "f32[?,1,?,16]", {{"axis", 2}});
    auto _gpt_neox_layers_1_attention_Mul_2 = GenPattern<opset1::Multiply>({_gpt_neox_layers_1_attention_Slice_5, _gpt_neox_layers_1_attention_GatherElements}, "f32[?,8,?,16]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Slice_10 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Slice_5, {8}, {2147483647}, {1}, {3}}, "f32[?,8,?,8]");
    auto _gpt_neox_layers_1_attention_Neg_1 = GenPattern<PowerStaticNode>({_gpt_neox_layers_1_attention_Slice_10}, "f32[?,8,?,8]", {{"scale", -1.0}, {"power", 1.0}, {"shift", 0.0}, {"out-type", "f32"}});
    auto _gpt_neox_layers_1_attention_Slice_9 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Slice_5, {0}, {8}, {1}, {3}}, "f32[?,8,?,8]");
    auto _gpt_neox_layers_1_attention_Concat_8 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Neg_1, _gpt_neox_layers_1_attention_Slice_9}, "f32[?,8,?,16]", {{"axis", -1}});
    auto _gpt_neox_layers_1_attention_rotary_emb_Slice_1 = GenPattern<opset8::Slice>({_gpt_neox_layers_0_attention_rotary_emb_Constant_5, {0}, _gpt_neox_layers_1_attention_Add, {1}, {0}}, "f32[..1,1,2048,16]");
    auto _gpt_neox_layers_1_attention_Concat_6 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Tile_shape__0__, {1}, {1}, {1}}, "i32[4]", {{"axis", 0}});
    auto _gpt_neox_layers_1_attention_Tile_2 = GenPattern<opset1::Tile>({_gpt_neox_layers_1_attention_rotary_emb_Slice_1, _gpt_neox_layers_1_attention_Concat_6}, "f32[?,1,2048,16]");
    auto _gpt_neox_layers_1_attention_GatherElements_1 = GenPattern<opset6::GatherElements>({_gpt_neox_layers_1_attention_Tile_2, _gpt_neox_layers_1_attention_Tile}, "f32[?,1,?,16]", {{"axis", 2}});
    auto _gpt_neox_layers_1_attention_Mul_3 = GenPattern<opset1::Multiply>({_gpt_neox_layers_1_attention_Concat_8, _gpt_neox_layers_1_attention_GatherElements_1}, "f32[?,8,?,16]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Add_2 = GenPattern<opset1::Add>({_gpt_neox_layers_1_attention_Mul_2, _gpt_neox_layers_1_attention_Mul_3}, "f32[?,8,?,16]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Slice_6 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Transpose_1, {16}, {2147483647}, {1}, {3}}, "f32[?,8,?,48]");
    auto _gpt_neox_layers_1_attention_Concat_10 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Add_2, _gpt_neox_layers_1_attention_Slice_6}, "f32[?,8,?,64]", {{"axis", -1}});
    auto present_1_key = GenPattern<opset1::Concat>({past_key_values_1_key, _gpt_neox_layers_1_attention_Concat_10}, "f32[?,8,?,64]", {{"axis", -2}});
    auto present_1_key_shape_n2_ = GenPattern<DimOfNode>({present_1_key}, "i32[1]", {{"axis", -2}, {"output_scalar", 0}});
    auto _gpt_neox_layers_1_attention_Slice = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Reshape, {0}, {64}, {1}, {3}}, "f32[?,?,8,64]");
    auto _gpt_neox_layers_1_attention_Transpose = GenPattern<opset1::Transpose>({_gpt_neox_layers_1_attention_Slice, {0, 2, 1, 3}}, "f32[?,8,?,64]");
    auto _gpt_neox_layers_1_attention_Slice_3 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Transpose, {0}, {16}, {1}, {3}}, "f32[?,8,?,16]");
    auto _gpt_neox_layers_1_attention_Mul = GenPattern<opset1::Multiply>({_gpt_neox_layers_1_attention_Slice_3, _gpt_neox_layers_1_attention_GatherElements}, "f32[?,8,?,16]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Slice_8 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Slice_3, {8}, {2147483647}, {1}, {3}}, "f32[?,8,?,8]");
    auto _gpt_neox_layers_1_attention_Neg = GenPattern<PowerStaticNode>({_gpt_neox_layers_1_attention_Slice_8}, "f32[?,8,?,8]", {{"scale", -1.0}, {"power", 1.0}, {"shift", 0.0}, {"out-type", "f32"}});
    auto _gpt_neox_layers_1_attention_Slice_7 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Slice_3, {0}, {8}, {1}, {3}}, "f32[?,8,?,8]");
    auto _gpt_neox_layers_1_attention_Concat_7 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Neg, _gpt_neox_layers_1_attention_Slice_7}, "f32[?,8,?,16]", {{"axis", -1}});
    auto _gpt_neox_layers_1_attention_Mul_1 = GenPattern<opset1::Multiply>({_gpt_neox_layers_1_attention_Concat_7, _gpt_neox_layers_1_attention_GatherElements_1}, "f32[?,8,?,16]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Add_1 = GenPattern<opset1::Add>({_gpt_neox_layers_1_attention_Mul, _gpt_neox_layers_1_attention_Mul_1}, "f32[?,8,?,16]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Slice_4 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Transpose, {16}, {2147483647}, {1}, {3}}, "f32[?,8,?,48]");
    auto _gpt_neox_layers_1_attention_Concat_9 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Add_1, _gpt_neox_layers_1_attention_Slice_4}, "f32[?,8,?,64]", {{"axis", -1}});
    auto _gpt_neox_layers_1_attention_Concat_9_shape__2__ = GenPattern<DimOfNode>({_gpt_neox_layers_1_attention_Concat_9}, "i32[1]", {{"axis", 2}, {"output_scalar", 0}});
    auto Multiply_59463 = GenPattern<opset1::Multiply>({_gpt_neox_layers_1_attention_Concat_9_shape__2__, -1}, "i32[1]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Sub = GenPattern<opset1::Add>({present_1_key_shape_n2_, Multiply_59463}, "i32[1]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Slice_12 = GenPattern<opset8::Slice>({gpt_neox_layers_1_attention_bias, _gpt_neox_layers_1_attention_Sub, present_1_key_shape_n2_, {1}, {2}}, "u8[1,1,..2048,2048]");
    auto _gpt_neox_layers_1_attention_Slice_13 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Slice_12, {0}, present_1_key_shape_n2_, {1}, {3}}, "u8[1,1,..2048,..2048]");
    auto _gpt_neox_layers_1_attention_Concat_9_shape__0__ = GenPattern<DimOfNode>({_gpt_neox_layers_1_attention_Concat_9}, "i32[1]", {{"axis", 0}, {"output_scalar", 0}});
    auto _gpt_neox_layers_1_attention_Mul_4 = GenPattern<opset1::Multiply>({_gpt_neox_layers_1_attention_Concat_9_shape__0__, 8}, "i32[1]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Concat_13 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Mul_4, _gpt_neox_layers_1_attention_Concat_9_shape__2__, {64}}, "i32[3]", {{"axis", 0}});
    auto _gpt_neox_layers_1_attention_Reshape_1 = GenPattern<opset1::Reshape>({_gpt_neox_layers_1_attention_Concat_9, _gpt_neox_layers_1_attention_Concat_13}, "f32[?,?,64]", {{"special_zero", 1}});
    auto Multiply_52923 = GenPattern<PowerStaticNode>({present_1_key}, "f32[?,8,?,64]", {{"scale", 0.125}, {"power", 1.0}, {"shift", 0.0}, {"out-type", "f32"}});
    auto _gpt_neox_layers_1_attention_Concat_14 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Mul_4, present_1_key_shape_n2_, {64}}, "i32[3]", {{"axis", 0}});
    auto _gpt_neox_layers_1_attention_Reshape_2 = GenPattern<opset1::Reshape>({Multiply_52923, _gpt_neox_layers_1_attention_Concat_14}, "f32[?,?,64]", {{"special_zero", 1}});
    auto _gpt_neox_layers_1_attention_Mul_5 = GenPattern<opset1::MatMul>({_gpt_neox_layers_1_attention_Reshape_1, _gpt_neox_layers_1_attention_Reshape_2}, "f32[?,?,?]", {{"transpose_a", 0}, {"transpose_b", 1}});
    auto _gpt_neox_layers_1_attention_Concat_16 = GenPattern<opset1::Concat>({_gpt_neox_layers_1_attention_Concat_9_shape__0__, {8}, _gpt_neox_layers_1_attention_Concat_9_shape__2__, present_1_key_shape_n2_}, "i32[4]", {{"axis", 0}});
    auto _gpt_neox_layers_1_attention_Reshape_3 = GenPattern<opset1::Reshape>({_gpt_neox_layers_1_attention_Mul_5, _gpt_neox_layers_1_attention_Concat_16}, "f32[?,8,?,?]", {{"special_zero", 1}});
    auto _gpt_neox_layers_1_attention_Where = GenPattern<opset1::Select>({_gpt_neox_layers_1_attention_Slice_13, _gpt_neox_layers_1_attention_Reshape_3, -FLT_MAX}, "f32[?,8,?,?]", {{"type_relax", 1}, {"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Add_4 = GenPattern<opset1::Add>({_gpt_neox_layers_1_attention_Where, _gpt_neox_Mul}, "f32[?,8,?,?]", {{"auto_broadcast", "numpy"}});
    auto _gpt_neox_layers_1_attention_Softmax = GenPattern<opset1::Softmax>({_gpt_neox_layers_1_attention_Add_4}, "f32[?,8,?,?]", {{"axis", 3}});
    auto _gpt_neox_layers_1_attention_Slice_2 = GenPattern<opset8::Slice>({_gpt_neox_layers_1_attention_Reshape, {128}, {2147483647}, {1}, {3}}, "f32[?,?,8,64]");
    auto _gpt_neox_layers_1_attention_Transpose_2 = GenPattern<opset1::Transpose>({_gpt_neox_layers_1_attention_Slice_2, {0, 2, 1, 3}}, "f32[?,8,?,64]");
    auto present_1_value = GenPattern<opset1::Concat>({past_key_values_1_value, _gpt_neox_layers_1_attention_Transpose_2}, "f32[?,8,?,64]", {{"axis", -2}});
    auto _gpt_neox_layers_1_attention_MatMul_1 = GenPattern<opset1::MatMul>({_gpt_neox_layers_1_attention_Softmax, present_1_value}, "f32[?,8,?,64]", {{"transpose_a", 0}, {"transpose_b", 0}});
    auto _gpt_neox_layers_1_attention_Transpose_4 = GenPattern<opset1::Transpose>({_gpt_neox_layers_1_attention_MatMul_1, {0, 2, 1, 3}}, "f32[?,?,8,64]");
    auto _gpt_neox_layers_1_attention_Reshape_4 = GenPattern<opset1::Reshape>({_gpt_neox_layers_1_attention_Transpose_4, {0, 0, 512}}, "f32[?,?,512]", {{"special_zero", 1}});


    return {_gpt_neox_layers_1_attention_Reshape_4, present_1_key, present_1_value};
}