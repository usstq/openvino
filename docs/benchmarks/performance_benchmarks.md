# Performance Benchmarks {#openvino_docs_performance_benchmarks}

@sphinxdirective

.. toctree::
   :maxdepth: 1
   :hidden:

   openvino_docs_performance_benchmarks_openvino
   openvino_docs_performance_benchmarks_ovms
   openvino_docs_MO_DG_Getting_Performance_Numbers


@endsphinxdirective

The [Intel® Distribution of OpenVINO™ toolkit](https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html) helps accelerate deep learning inference across a variety of Intel® processors and accelerators.

The benchmark results below demonstrate high performance gains on several public neural networks on multiple Intel® CPUs, GPUs and VPUs covering a broad performance range. The results may be helpful when deciding which hardware is best for your applications and solutions or to plan AI workload on the Intel computing already included in your solutions.

Benchmarks are available for:

* [Intel® Distribution of OpenVINO™ toolkit](performance_benchmarks_openvino.md).
* [OpenVINO™ Model Server](performance_benchmarks_ovms.md).


You can also test performance for your system yourself, following the guide on [getting performance numbers](../MO_DG/prepare_model/Getting_performance_numbers.md).
Performance of a particular application can also be evaluated virtually using [Intel® DevCloud for the Edge](https://devcloud.intel.com/edge/). It is a remote development environment with access to Intel® hardware and the latest versions of the Intel® Distribution of the OpenVINO™ Toolkit. To learn more about it, visit [the website](https://www.intel.com/content/www/us/en/developer/tools/devcloud/edge/overview.html) or [create an account](https://www.intel.com/content/www/us/en/forms/idz/devcloud-registration.html?tgt=https://www.intel.com/content/www/us/en/secure/forms/devcloud-enrollment/account-provisioning.html).

